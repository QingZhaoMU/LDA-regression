rm(list=ls())
library(boot)

path <- 'c:/'

nsim <- 100

niter <- 5000
nburn <- round(niter * .8)
adapt <- round(niter * .5)

#==============
# basic values
#==============
nc <- 4 # number of communities
nx <- 5 # number of covariates plus one
        # the first column for x is always 1, for intercept

nl <- 500 # number of sites
ns <- 200 # number of species
nm <- matrix(5, nl, ns) # number of surveys per site
sigma <- 1 # standard deviation of the errors in logistic regression

for (k in 1:nsim) {
#=================
# data simulation
#=================
# beta's, the first row is the intercept
beta <- matrix(runif(nx*(nc-1), -1, 1), nrow=nx, ncol=nc-1)

# covariates, the first column is 1 for the intercept
x <- cbind(1, matrix(rnorm(nl*(nx-1), 0, 1), nrow=nl, ncol=nx-1))

# theta, proportion of communities for each site
mu <- x %*% beta
z <- matrix(rnorm(nl*(nc-1), mu, sigma),nrow=nl,ncol=nc-1)
vmat <- cbind(exp(z),1)
theta <- vmat / rowSums(vmat)
#colMeans(theta)

# phi, proportion of species for each community
phi <- matrix(rbeta(nc*ns, .2, .8), nrow=nc, ncol=ns)

# pi, probability of occurrence for a species in a site
pi <- theta %*% phi

# number of detections during nmat surveys
y <- matrix(rbinom(nl*ns, nm, pi), nrow=nl, ncol=ns)

#==================
# define functions
#==================
#generates multivariate normal with mean 0 and Sigma=sqrtVar1%*%t(sqrtVar1)
rmvnorm1 <- function (sqrtVar1) {
  sqrtVar1 %*% rnorm(ncol(sqrtVar1))
} # rmvnorml

tnorm <- function(n, lo, hi, mu, sig) {
  # generates truncated normal variates based on cumulative normal distribution normal truncated lo and hi

  if (length(lo) == 1 & length(mu) > 1) 
    lo <- rep(lo, length(mu))
  if (length(hi) == 1 & length(mu) > 1) 
    hi <- rep(hi, length(mu))
    
  q1 <- pnorm(lo, mu, sig)  #cumulative distribution
  q2 <- pnorm(hi, mu, sig)  #cumulative distribution
    
  z <- runif(n, q1, q2)
  z <- qnorm(z, mu, sig)
  z[z == -Inf] <- lo[z == -Inf]
  z[z == Inf] <- hi[z == Inf]
  z
} # tnorm

fix.MH <- function(lo, hi, old1, new1, jump) {
  jold <- pnorm(hi, mean = old1, sd = jump) - pnorm(lo, mean = old1, sd = jump)
  jnew <- pnorm(hi, mean = new1, sd = jump) - pnorm(lo, mean = new1, sd = jump)
  log(jold) - log(jnew)  #add this to pnew
} # fix.MH

get.logl <- function(theta, phi, y, nm) {
  prob <- theta %*% phi
  cond <- prob < 1e-05
  prob[cond] <- 1e-05
  cond <- prob > 0.99999
  prob[cond] <- 0.99999
  dbinom(y, size = nm, prob = prob, log = T)
} # get.logl

acceptMH <- function(p0, p1, x0, x1, BLOCK) {
  # accept for M, M-H if BLOCK, then accept as a block, otherwise, accept individually
    
  nz <- length(x0)  #no. to accept
  if (BLOCK) 
    nz <- 1
    
  a <- exp(p1 - p0)  #acceptance PR
  z <- runif(nz, 0, 1)
  keep <- which(z < a)
    
  if (BLOCK & length(keep) > 0) 
    x0 <- x1
  if (!BLOCK) 
    x0[keep] <- x1[keep]
  accept <- length(keep)
    
  list(x = x0, accept = accept)
} # acceptMH

update.theta <- function(param, jump, nl, nc, y, x, nm) {
  phi <- param$phi
  beta <- param$beta
  mu <- x %*% beta

  z.ori <- z.old <- param$z
  vmat.old=cbind(exp(z.old),1)
  
  z.tmp = rnorm(nl*(nc-1), mean=z.old, sd=jump)
  z.proposed = matrix(z.tmp,nrow=nl,ncol=nc-1)
  vmat.proposed <- cbind(exp(z.proposed),1)

  for (j in 1:(nc-1)) {
    # last column has to be 1
    vmat.new <- vmat.old
    vmat.new[,j] <- vmat.proposed[,j]

    theta.old <- vmat.old / rowSums(vmat.old)
    theta.new <- vmat.new / rowSums(vmat.new)

    prob.old <- get.logl(theta=theta.old, phi=phi, y=y, nm=nm)
    prob.new <- get.logl(theta=theta.new, phi=phi, y=y, nm=nm)

    pold <- rowSums(prob.old) + dnorm(log(vmat.old[,j]), mu[,j], sigma, log = T)
    pnew <- rowSums(prob.new) + dnorm(log(vmat.new[,j]), mu[,j], sigma, log = T)

    k <- acceptMH(p0=pold, p1=pnew, x0=vmat.old[,j], x1=vmat.new[,j], BLOCK=F)
    vmat.old[,j] <- k$x
  }

  vmat <- vmat.old
  theta <- vmat / rowSums(vmat)
  z = log(vmat)[,-nc]
  list(theta=theta, z=z, accept=z.ori!=log(vmat.old[,-nc]))
} # update.theta

update.phi <- function(param, jump, nc, ns, y, nm, a.phi, b.phi) {
  theta <- param$theta

  phi.ori <- phi.old <- param$phi
  proposed <- matrix(tnorm(nc*ns, lo=0, hi=1, mu=phi.old, sig=jump), nc, ns)
  adj <- fix.MH(lo=0, hi=1, old1=phi.old, new1=proposed, jump=jump)

  for (j in 1:nc) {
    phi.new <- phi.old
    phi.new[j,] <- proposed[j,]

    prob.old <- get.logl(theta=theta, phi=phi.old, y=y, nm=nm)
    prob.new <- get.logl(theta=theta, phi=phi.new, y=y, nm=nm)

    pold <- colSums(prob.old) + dbeta(phi.old[j,], a.phi, b.phi, log=T)
    pnew <- colSums(prob.new) + dbeta(phi.new[j,], a.phi, b.phi, log=T)

    k <- acceptMH(p0=pold, p1=pnew + adj[j,], x0=phi.old[j,], x1=phi.new[j,], BLOCK=F)
    phi.old[j,] <- k$x
  }
  phi <- phi.old
  list(phi=phi, accept=phi.ori!=phi.old)
} # update.phi

update.beta <- function(param, nx, nc, tx, sqrtVar1, var1) {
  z <- param$z
  
  beta=matrix(, nx, nc-1)
  for (i in 1:(nc-1)){
    pmean <- tx%*%z[,i]
    beta[,i] <- rmvnorm1(sqrtVar1) + var1%*%pmean
  }
  beta 
} # update.beta

jumpTune <- function(accept, jump, ni, low=.3, high=.8) {
  nstart <- ifelse(ni>=100, ni-99, 1)
  accept.rate <- apply(accept[,,nstart:ni], 1:2, mean)
  jump[accept.rate < low]  <- jump[accept.rate < low] * 0.5 
  jump[accept.rate > high] <- jump[accept.rate > high] * 2
  jump
} # jumpTune

#===========
# run model
#===========
z.jump <- matrix(.05, nrow=nl, ncol=nc-1)
phi.jump <- matrix(.05, nrow=nc, ncol=ns)

param <- list()

param$z <- matrix(0,nl,nc-1)
param$theta <- matrix(1/nc,nl,nc)
param$phi <- matrix(0.5,nc,ns)
param$beta <- matrix(0,nx,nc-1)

theta.post <- array(, dim=c(nl, nc, niter))
theta.post[,,1] <- param$theta

z.jump.post <- z.accept <- array(, dim=c(nl, nc-1, niter))
z.jump.post[,,1] = z.jump
z.accept[,,1] <- FALSE

phi.post <- phi.jump.post <- phi.accept <- array(, dim=c(nc, ns, niter))
phi.post[,,1] <- param$phi
phi.jump.post[,,1] <- phi.jump
phi.accept[,,1] <- FALSE

beta.post <- array(, dim=c(nx, nc-1, niter))
beta.post[,,1] <- param$beta

#pre-calculate useful stuff
# prior for regression parameters
invT=diag(1,nx)
invT[1,1]=1/25

#pre-calculate variance of regression parameters
tx=t(x)
xtx=tx%*%x
var1=solve(xtx+invT)
s. <- svd(var1)
sqrtVar1=s.$u %*% diag(sqrt(s.$d))

pb <- txtProgressBar(min=0, max=nburn, style=3)

for (i in 2:niter) {
  setTxtProgressBar(pb, i)

  tmp <- update.theta(param, jump=z.jump, nl, nc, y, x, nm)
  param$z = tmp$z
  theta.post[,,i] <- param$theta <- tmp$theta
  z.accept[,,i] <- tmp$accept

  tmp <- update.phi(param, jump=phi.jump, nc, ns, y, nm, a.phi=1, b.phi=1)
  phi.post[,,i] <- param$phi <- tmp$phi
  phi.accept[,,i] <- tmp$accept

  beta.tmp <- update.beta(param, nx, nc, tx, sqrtVar1, var1)
  beta.post[,,i] <- param$beta <- beta.tmp

  #tune jump parameter
  if (i < adapt & i%%100==0){
    tmp <- jumpTune(accept=z.accept, jump=z.jump, ni=i, low=.3, high=.8)
    z.jump.post[,,i] <- z.jump <- tmp
  
    tmp <- jumpTune(accept=phi.accept, jump=phi.jump, ni=i, low=.3, high=.8)
    phi.jump.post[,,i] <- phi.jump <- tmp
  }
}

#===============
# check results
#===============
beta.est <- beta.post[,,(nburn+1):niter]

nl.res <- 100

pdf(file=paste(c(path, 'sim response curve_', k, '.pdf'), collapse=''), width=6, height=5)

par(mfrow=c(2,2))
par(mar=c(4,4,1,1))

for (i in 1:(nx-1)) {
  x.res <- cbind(1, matrix(0, nl.res, nx-1))
  x.res[,i+1] <- seq(-2, 2, length.out=nl.res)

  mu.res.true <- x.res %*% beta
  vmat.res.true <- cbind(exp(mu.res.true), 1)
  theta.res.true <- vmat.res.true / rowSums(vmat.res.true)

  theta.res <- array(, dim=c(nl.res, nc, dim(beta.est)[3]))
  for (m in 1:dim(beta.est)[3]) {
    mu.res <- x.res %*% beta.est[,,m]
    vmat.res <- cbind(exp(mu.res), 1)
    theta.res[,,m] <- vmat.res / rowSums(vmat.res)
  }
  theta.res.qt <- apply(theta.res, 1:2, quantile, probs=c(.025, .975))

  plot(theta.res.true[,1] ~ x.res[,i+1], ylim=range(c(theta.res.true,theta.res.qt)), 
       type='n', xlab=paste('X', i, sep=''), ylab='Theta')
  for (j in 1:nc) {
    rgb <- as.vector(col2rgb(j+1))
    col <- rgb(red=rgb[1], green=rgb[2], blue=rgb[3], alpha=255*.36, maxColorValue=255)
    polygon(x=c(x.res[,i+1],rev(x.res[,i+1])), 
            y=c(theta.res.qt[1,,j],rev(theta.res.qt[2,,j])), border=NA, col=col)
  }
  for (j in 1:nc) {
    lines(theta.res.true[,j] ~ x.res[,i+1], col=j+1, lwd=2)
  }
} # i

dev.off()

par(mfrow=c(nx,nc-1))
par(mar=c(0,0,0,0))
for (i in 1:nx) {
  for (j in 1:(nc-1)) {
    plot(beta.post[i,j,], type='l')
  }
}

} # k


